# ğŸš¢ Titanic Survival Prediction using KNN

A complete beginner-friendly machine learning project to predict whether a passenger survived the Titanic disaster using the **K-Nearest Neighbors (KNN)** algorithm.

This project is part of my data science learning journey.

---

# ğŸ“˜ Project Overview

This project uses the Kaggle Titanic dataset to:

* Clean and preprocess data
* Create new features
* Encode categorical variables
* Scale numerical values
* Tune KNN (k = 1 to 20)
* Train the final model
* Generate a prediction file for Kaggle

The complete implementation is inside the Jupyter Notebook: **titanic.ipynb**.

---

# ğŸ“‚ Project Files

```
â”œâ”€â”€ titanic.ipynb          # Notebook with all code
â”œâ”€â”€ submission.csv         # Final predictions for Kaggle
â””â”€â”€ README.md              # Project documentation
```

---

# ğŸ¯ Objective

To build a machine learning model that predicts the survival of Titanic passengers using simple, clean preprocessing steps and the KNN algorithm.

Dataset: **Kaggle Titanic Competition**.

---

# ğŸ§¹ Data Preprocessing

### âœ” Handle Missing Values

* `Age`: filled using median
* `Fare`: filled using median
* `Embarked`: filled using mode

### âœ” New Feature

* `HasCabin` â†’ 1 if cabin present, 0 if missing

### âœ” Encoding

Applied **One-Hot Encoding** to:

* `Sex`
* `Embarked`

### âœ” Scaling

Used **StandardScaler** to normalize numerical features.

---

# ğŸ§¾ Features Used in the Model

* `Pclass`
* `Age`
* `SibSp`
* `Parch`
* `Fare`
* `HasCabin`
* `Sex_male`
* `Embarked_Q`
* `Embarked_S`

---

# ğŸ¤– Machine Learning Model â€“ KNN

KNN works by comparing the distance between passengers in the dataset.

### ğŸ”§ Model Tuning

Tried **k from 1 to 20** and selected the value with the best validation accuracy.

### ğŸ“Œ Final Model Parameter

```
n_neighbors = 15
```

*(Your value may differ based on tuning)*

---

# ğŸ“„ Kaggle Submission

The notebook generates a file:

```
submission.csv
```

Upload this to Kaggle â†’ Submit Predictions.

---

# ğŸ›  How to Run This Project

### **1ï¸âƒ£ Download the dataset from Kaggle**

Get `train.csv` and `test.csv`.

### **2ï¸âƒ£ Open the notebook**

Use Jupyter Notebook or VS Code.

```
jupyter notebook titanic_knn.ipynb
```

### **3ï¸âƒ£ Install required libraries**

```
pip install pandas numpy scikit-learn
```

### **4ï¸âƒ£ Run all cells**

Click **Run All**.

### **5ï¸âƒ£ Get submission file**

After running, the notebook creates **submission.csv**.

---

# ğŸ“ˆ Results

* Completed full preprocessing pipeline
* Built and tuned a KNN model
* Generated valid Kaggle predictions
* Typical leaderboard score: **0.64 â€“ 0.70**

---

# ğŸš€ Future Improvements

* Try Logistic Regression / Random Forest / XGBoost
* Add cross-validation
* Perform GridSearchCV tuning
* Add data visualization

---

# ğŸ“¬ Contact

Feel free to connect with me on LinkedIn!

If you found this project useful, â­ star the repo!
